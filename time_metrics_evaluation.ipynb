{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación de Métricas Temporales para SPMV\n",
    "\n",
    "Este notebook evalúa el impacto del tiempo de ejecución en la calidad de los modelos de clasificación para SPMV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install odfpy\n",
    "!pip install ultralytics\n",
    "!git clone https://github.com/DiazCerecetto/SPMV.git\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/content/SPMV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spmv.config import Config\n",
    "from spmv.dataset import DatasetManager\n",
    "from spmv.images import ImageManager\n",
    "from spmv.time_metrics import TimeMetricsEvaluator\n",
    "\n",
    "# Initialize configuration and managers\n",
    "config = Config()\n",
    "image_manager = ImageManager()\n",
    "dataset_manager = DatasetManager(config, image_manager)\n",
    "time_evaluator = TimeMetricsEvaluator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = dataset_manager.leer_datasets()\n",
    "\n",
    "# Load original data for time information\n",
    "data_original = pd.read_csv(config.ARCHIVO_ENTRADA)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"\\nClase más frecuente en train: {y_train.mode()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Evaluación usando predicción de clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_metrics = time_evaluator.evaluate_majority_class(y_test, data_original)\n",
    "\n",
    "print(\"Métricas para predicción de clase mayoritaria:\")\n",
    "print(f\"Accuracy: {majority_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1 (macro): {majority_metrics['f1_macro']:.4f}\")\n",
    "print(f\"Penalización temporal promedio: {majority_metrics['avg_time_penalty']:.4f}\")\n",
    "print(f\"Accuracy ponderado por tiempo: {majority_metrics['time_weighted_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluación usando Random Forest con todas las características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metrics = time_evaluator.evaluate_random_forest(\n",
    "    X_train, y_train, X_test, y_test, data_original\n",
    ")\n",
    "\n",
    "print(\"\\nMétricas para Random Forest:\")\n",
    "print(f\"Accuracy: {rf_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1 (macro): {rf_metrics['f1_macro']:.4f}\")\n",
    "print(f\"Penalización temporal promedio: {rf_metrics['avg_time_penalty']:.4f}\")\n",
    "print(f\"Accuracy ponderado por tiempo: {rf_metrics['time_weighted_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluación usando Random Forest solo con características HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas HOG\n",
    "hog_columns = [col for col in X_train.columns if 'hog' in col.lower()]\n",
    "print(f\"Número de características HOG: {len(hog_columns)}\")\n",
    "\n",
    "hog_metrics = time_evaluator.evaluate_hog_random_forest(\n",
    "    X_train, y_train, X_test, y_test, data_original, hog_columns\n",
    ")\n",
    "\n",
    "print(\"\\nMétricas para Random Forest con HOG:\")\n",
    "print(f\"Accuracy: {hog_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1 (macro): {hog_metrics['f1_macro']:.4f}\")\n",
    "print(f\"Penalización temporal promedio: {hog_metrics['avg_time_penalty']:.4f}\")\n",
    "print(f\"Accuracy ponderado por tiempo: {hog_metrics['time_weighted_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Método': ['Clase Mayoritaria', 'Random Forest', 'RF + HOG'],\n",
    "    'Accuracy': [\n",
    "        majority_metrics['accuracy'],\n",
    "        rf_metrics['accuracy'],\n",
    "        hog_metrics['accuracy']\n",
    "    ],\n",
    "    'F1 (macro)': [\n",
    "        majority_metrics['f1_macro'],\n",
    "        rf_metrics['f1_macro'],\n",
    "        hog_metrics['f1_macro']\n",
    "    ],\n",
    "    'Penalización Temporal': [\n",
    "        majority_metrics['avg_time_penalty'],\n",
    "        rf_metrics['avg_time_penalty'],\n",
    "        hog_metrics['avg_time_penalty']\n",
    "    ],\n",
    "    'Accuracy Temporal': [\n",
    "        majority_metrics['time_weighted_accuracy'],\n",
    "        rf_metrics['time_weighted_accuracy'],\n",
    "        hog_metrics['time_weighted_accuracy']\n",
    "    ]\n",
    "})\n",
    "\n",
    "results.style.format({\n",
    "    'Accuracy': '{:.4f}',\n",
    "    'F1 (macro)': '{:.4f}',\n",
    "    'Penalización Temporal': '{:.4f}',\n",
    "    'Accuracy Temporal': '{:.4f}'\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
